{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVDI3kfZ0iZX"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"cognitiveclass.ai logo\">\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "marked": true
        },
        "id": "XZYFSzaY0iZb"
      },
      "source": [
        "# Machine Learning Foundation\n",
        "\n",
        "## Course 4, Part e: Non-Negative Matrix Factorization DEMO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9aBiOJj0iZc"
      },
      "source": [
        "This exercise illustrates usage of Non-negative Matrix factorization and covers techniques related to sparse matrices and some basic work with Natural Langauge Processing.  We will use NMF to look at the top words for given topics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks-7B2gj0iZc"
      },
      "source": [
        "## Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lefOuHFs0iZd"
      },
      "source": [
        "We'll be using the BBC dataset. These are articles collected from 5 different topics, with the data pre-processed.\n",
        "\n",
        "These data are available in the data folder (or online [here](http://mlg.ucd.ie/files/datasets/bbc.zip?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01)). The data consists of a few files. The steps we'll be following are:\n",
        "\n",
        "* *bbc.terms* is just a list of words\n",
        "* *bbc.docs* is a list of artcles listed by topic.\n",
        "\n",
        "At a high level, we're going to\n",
        "\n",
        "1. Turn the `bbc.mtx` file into a sparse matrix (a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) format can be useful for matrices with many values that are 0, and save space by storing the position and values of non-zero elements).\n",
        "1. Decompose that sparse matrix using NMF.\n",
        "1. Use the resulting components of NMF to analyze the topics that result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rLzXtGV0iZd"
      },
      "source": [
        "## Data Setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Ywusys0iZd"
      },
      "source": [
        "Note: This lab has been updated to work in skillsnetwork for your convenience.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ev6uYP5J0iZe"
      },
      "outputs": [],
      "source": [
        "import urllib # Nhập thư viện urllib để làm việc với URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "HEChNv-U0iZf"
      },
      "outputs": [],
      "source": [
        "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.mtx') as r:\n",
        "    content = r.readlines()[2:] # Đọc nội dung từ URL, bỏ qua 2 dòng đầu tiên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjBTbD-b0iZf"
      },
      "source": [
        "## Part 1\n",
        "\n",
        "Here, we will turn this into a list of tuples representing a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01). Remember the description of the file from above:\n",
        "\n",
        "* *bbc.mtx* is a list: first column is **wordID**, second is **articleID** and the third is the number of times that word appeared in that article.\n",
        "\n",
        "So, if word 1 appears in article 3, 2 times, one element of our list will be:\n",
        "\n",
        "`(1, 3, 2)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90chTLgi0iZg",
        "outputId": "980cc6f7-6963-4c23-c0cd-b36e24565131"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 1, 1),\n",
              " (1, 7, 2),\n",
              " (1, 11, 1),\n",
              " (1, 14, 1),\n",
              " (1, 15, 2),\n",
              " (1, 19, 2),\n",
              " (1, 21, 1),\n",
              " (1, 29, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "sparsemat = [tuple(map(int,map(float,c.split()))) for c in content] # Chuyển đổi nội dung thành danh sách các tuple (wordID, articleID, count)\n",
        "# Let's examine the first few elements\n",
        "sparsemat[:8] # Hiển thị 8 phần tử đầu tiên của danh sách"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD79kf7X0iZg"
      },
      "source": [
        "## Part 2: Preparing Sparse Matrix data for NMF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8ww7DEW0iZg"
      },
      "source": [
        "We will use the [coo matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) function to turn the sparse matrix into an array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dmfthJev0iZg"
      },
      "outputs": [],
      "source": [
        "import numpy as np # Nhập thư viện numpy\n",
        "from scipy.sparse import coo_matrix # Nhập coo_matrix từ scipy.sparse\n",
        "rows = [x[0] for x in sparsemat] # Lấy danh sách các wordID\n",
        "cols = [x[1] for x in sparsemat] # Lấy danh sách các articleID\n",
        "values = [x[2] for x in sparsemat] # Lấy danh sách các count\n",
        "coo = coo_matrix((values, (rows, cols))) # Tạo ma trận thưa (sparse matrix) từ dữ liệu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQOsY6bp0iZh"
      },
      "source": [
        "## NMF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtwyXJiU0iZh"
      },
      "source": [
        "NMF is a way of decomposing a matrix of documents and words so that one of the matrices can be interpreted as the \"loadings\" or \"weights\" of each word on a topic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW9wSQ5q0iZh"
      },
      "source": [
        "Check out [the NMF documentation](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) and the [examples of topic extraction using NMF and LDA](http://scikit-learn.org/0.18/auto_examples/applications/topics_extraction_with_nmf_lda.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTFzh3BV0iZh"
      },
      "source": [
        "## Part 3\n",
        "\n",
        "Here, we will import `NMF`, define a model object with 5 components, and `fit_transform` the data created above.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZZ4tAo00iZh",
        "outputId": "af94261d-f771-4ed4-c66d-4d489aca9938"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9636, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Surpress warnings from using older version of sklearn:\n",
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn # Bỏ qua các cảnh báo\n",
        "\n",
        "from sklearn.decomposition import NMF # Nhập NMF từ sklearn.decomposition\n",
        "model = NMF(n_components=5, init='random', random_state=818) # Khởi tạo mô hình NMF với 5 thành phần\n",
        "doc_topic = model.fit_transform(coo) # Áp dụng NMF lên ma trận thưa để phân rã\n",
        "\n",
        "doc_topic.shape # In ra kích thước của ma trận kết quả\n",
        "# we should have 9636 observations (articles) and five latent features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CtFmFyu0iZh",
        "outputId": "8795a9ed-dfdb-4f42-8f7e-fc40a098032e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, ..., 4, 4, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# find feature with highest value per doc\n",
        "np.argmax(doc_topic, axis=1) # Tìm chỉ số của giá trị lớn nhất trên mỗi hàng (mỗi tài liệu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaWAz07v0iZh"
      },
      "source": [
        "## Part 4:\n",
        "\n",
        "Check out the `components` of this model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_z3Upd20iZh",
        "outputId": "16e1dea6-328d-4008-eb71-76ab7eeebdcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 2226)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model.components_.shape # In ra kích thước của ma trận các thành phần (components) của mô hình NMF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZKU1k-70iZi"
      },
      "source": [
        "This is five rows, each of which is a \"topic\" containing the weights of each word on that topic. The exercise is to _get a list of the top 10 words for each topic_. We can just store this in a list of lists.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riTFKEKU0iZi"
      },
      "source": [
        "**Note:** Just like we read in the data above, we'll have to read in the words from the `bbc.terms` file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gt-wGqnN0iZi"
      },
      "outputs": [],
      "source": [
        "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.terms') as r:\n",
        "    content = r.readlines() # Đọc nội dung từ file bbc.terms\n",
        "words = [c.split()[0] for c in content] # Lấy danh sách các từ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "IfMmTCF_0iZi"
      },
      "outputs": [],
      "source": [
        "topic_words = [] # Khởi tạo danh sách rỗng để lưu trữ các từ hàng đầu cho mỗi chủ đề\n",
        "for r in model.components_: # Lặp qua từng hàng (chủ đề) trong ma trận components\n",
        "    a = sorted([(v,i) for i,v in enumerate(r)],reverse=True)[0:12] # Sắp xếp các từ theo trọng số giảm dần và lấy 12 từ hàng đầu\n",
        "    topic_words.append([words[e[1]] for e in a]) # Thêm danh sách các từ hàng đầu vào topic_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_J_ww1g0iZi",
        "outputId": "8e2eea44-0521-49df-dac1-cb50db336d2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[b'bondi',\n",
              "  b'stanlei',\n",
              "  b'continent',\n",
              "  b'mortgag',\n",
              "  b'bare',\n",
              "  b'least',\n",
              "  b'extent',\n",
              "  b'200',\n",
              "  b'leav',\n",
              "  b'frustrat',\n",
              "  b'yuan',\n",
              "  b'industri'],\n",
              " [b'manipul',\n",
              "  b'teenag',\n",
              "  b'drawn',\n",
              "  b'go',\n",
              "  b'prosecutor',\n",
              "  b'herbert',\n",
              "  b'host',\n",
              "  b'protest',\n",
              "  b'hike',\n",
              "  b'nation',\n",
              "  b'calcul',\n",
              "  b'power'],\n",
              " [b'dimens',\n",
              "  b'hous',\n",
              "  b'march',\n",
              "  b'wider',\n",
              "  b'owner',\n",
              "  b'intend',\n",
              "  b'declin',\n",
              "  b'forc',\n",
              "  b'posit',\n",
              "  b'founder',\n",
              "  b'york',\n",
              "  b'unavail'],\n",
              " [b'rome',\n",
              "  b'ft',\n",
              "  b'regain',\n",
              "  b'lawmak',\n",
              "  b'outright',\n",
              "  b'resum',\n",
              "  b'childhood',\n",
              "  b'greatest',\n",
              "  b'citi',\n",
              "  b'stagnat',\n",
              "  b'crown',\n",
              "  b'bodi'],\n",
              " [b'build',\n",
              "  b'empir',\n",
              "  b'isol',\n",
              "  b'\\xc2\\xa312',\n",
              "  b'restructur',\n",
              "  b'closer',\n",
              "  b'plung',\n",
              "  b'depreci',\n",
              "  b'durham',\n",
              "  b'race',\n",
              "  b'juli',\n",
              "  b'segreg']]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Here, each set of words relates to the corresponding topic (ie the first set of words relates to topic 'Business', etc.)\n",
        "topic_words[:5] # Hiển thị 5 danh sách từ hàng đầu đầu tiên"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0foK-d7o0iZi"
      },
      "source": [
        "The original data had 5 topics, as listed in `bbc.docs` (which these topic words relate to).\n",
        "\n",
        "```\n",
        "Business\n",
        "Entertainment\n",
        "Politics\n",
        "Sport\n",
        "Tech\n",
        "```\n",
        "\n",
        "In \"real life\", we would have found a way to use these to inform the model. But for this little demo, we can just compare the recovered topics to the original ones. And they seem to match reasonably well. The order is different, which is to be expected in this kind of model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsRr7tPj0iZi",
        "outputId": "e8ca08b5-39b9-436e-e696-105ceac42855"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'business.001\\n',\n",
              " b'business.002\\n',\n",
              " b'business.003\\n',\n",
              " b'business.004\\n',\n",
              " b'business.005\\n',\n",
              " b'business.006\\n',\n",
              " b'business.007\\n',\n",
              " b'business.008\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "with urllib.request.urlopen('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%203/data/bbc.docs') as r:\n",
        "    doc_content = r.readlines() # Đọc nội dung từ file bbc.docs\n",
        "\n",
        "doc_content[:8] # Hiển thị 8 dòng đầu tiên của nội dung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvnTMEf90iZi"
      },
      "source": [
        "---\n",
        "### Machine Learning Foundation (C) 2020 IBM Corporation\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}